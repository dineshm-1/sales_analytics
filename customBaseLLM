from langchain_core.language_models import BaseLanguageModel
from langchain_core.outputs import Generation, LLMResult
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field, SecretStr
from typing import Any, Dict, List, Optional
import requests
import os

class CustomLLMConfig(BaseModel):
    base_url: str = Field(..., description="Base URL for the API")
    api_key: SecretStr = Field(..., description="API key for authentication")

class CustomLLM(BaseLanguageModel):
    config: CustomLLMConfig
    tools: List[Any] = []

    def __init__(self, base_url: str, api_key: Optional[str] = None, **kwargs):
        if api_key is None:
            api_key = os.getenv("CUSTOM_LLM_API_KEY")
        if api_key is None:
            raise ValueError("API key must be provided or set as environment variable 'CUSTOM_LLM_API_KEY'.")
        super().__init__(config=CustomLLMConfig(base_url=base_url, api_key=api_key), **kwargs)
        self.tools = []

    def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs) -> str:
        headers = self._get_auth_headers()
        payload = {
            "prompt": prompt,
            "tools": self._get_tool_schemas() if self.tools else None
        }
        if stop:
            payload["stop"] = stop
        url = f"{self.config.base_url}/generate"
        try:
            response = requests.post(url, json=payload, headers=headers)
            response.raise_for_status()
            return response.json().get("text", "")
        except requests.RequestException as e:
            raise ValueError(f"API call failed: {str(e)}")

    def _generate(self, prompts: List[str], stop: Optional[List[str]] = None, **kwargs) -> LLMResult:
        generations = []
        for prompt in prompts:
            text = self._call(prompt, stop=stop, **kwargs)
            generations.append([Generation(text=text)])
        return LLMResult(generations=generations)

    async def _agenerate(self, prompts: List[str], stop: Optional[List[str]] = None, **kwargs) -> LLMResult:
        return self._generate(prompts, stop=stop, **kwargs)

    def bind_tools(self, tools: List[Any], **kwargs) -> 'CustomLLM':
        self.tools = tools
        return self

    def _get_auth_headers(self) -> Dict[str, str]:
        return {
            "Authorization": f"Bearer {self.config.api_key.get_secret_value()}",
            "Content-Type": "application/json"
        }

    def _get_tool_schemas(self) -> List[Dict[str, Any]]:
        schemas = []
        for tool in self.tools:
            if isinstance(tool, BaseTool):
                schema = {
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": tool.args_schema.schema() if tool.args_schema else {}
                    }
                }
            elif isinstance(tool, dict):
                schema = tool
            else:
                raise ValueError(f"Unsupported tool type: {type(tool)}")
            schemas.append(schema)
        return schemas

    @property
    def _llm_type(self) -> str:
        return "custom_llm"
